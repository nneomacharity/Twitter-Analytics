{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qHmOzDgRu6iq"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "\n",
        "# Set the maximum number of rows to read at a time\n",
        "chunksize = 1000\n",
        "\n",
        "# Create an empty DataFrame to store the data\n",
        "Similarity = pd.DataFrame()\n",
        "\n",
        "# Loop over the CSV file and read in chunks of 1000 rows\n",
        "for chunk in pd.read_csv('/content/merged_file.csv', chunksize=chunksize):\n",
        "    # Append the current chunk to the DataFrame\n",
        "    Similarity = Similarity.append(chunk, ignore_index=True)\n",
        "\n",
        "\n",
        "    # Stop reading the file if we have read in the maximum number of rows\n",
        "    if len(Similarity) >= 1000:\n",
        "        break\n",
        "\n",
        "# Enter the keywords to search\n",
        "kw1 = input(\"Enter first keyword: \")\n",
        "kw2 = input(\"Enter second keyword: \")\n",
        "\n",
        "#def similarity_analysis(Similarity):\n",
        "  \n",
        "# Extract tweets for the first keyword\n",
        "tweets_kw1 = Similarity.loc[Similarity['full_text'].str.contains(kw1, case=False)]\n",
        "if len(tweets_kw1) == 0:\n",
        "    print(f\"No tweets found for '{kw1}'\")\n",
        "    exit()\n",
        "\n",
        "# Extract tweets for the second keyword\n",
        "tweets_kw2 = Similarity.loc[Similarity['full_text'].str.contains(kw2, case=False)]\n",
        "if len(tweets_kw2) == 0:\n",
        "    print(f\"No tweets found for '{kw2}'\")\n",
        "    exit()\n",
        "\n",
        "# Combine the tweets into two lists\n",
        "docs1 = tweets_kw1['full_text'].tolist()\n",
        "docs2 = tweets_kw2['full_text'].tolist()\n",
        "\n",
        "# Create a TF-IDF vectorizer\n",
        "vectorizer = TfidfVectorizer(stop_words='english')\n",
        "\n",
        "# fit the vectorizer on the documents\n",
        "vectorizer.fit(docs1 + docs2)\n",
        "\n",
        "# transform the documents into TF-IDF vectors\n",
        "tfidf_matrix1 = vectorizer.transform(docs1)\n",
        "tfidf_matrix2 = vectorizer.transform(docs2)\n",
        "\n",
        "# compute the cosine similarity between the TF-IDF vectors\n",
        "cosine_sim = cosine_similarity(tfidf_matrix1, tfidf_matrix2)\n",
        "\n",
        "# plot the heatmap\n",
        "fig, ax = plt.subplots(figsize=(25,10))\n",
        "sns.heatmap(cosine_sim, cmap='YlOrBr') \n",
        "plt.title(f\"Similarity Between Tweets having '{kw1}' and '{kw2}'\")\n",
        "plt.show()\n",
        "\n",
        "# get the indices of the most similar tweets\n",
        "idx = cosine_sim.argmax(axis=1)\n"
      ]
    }
  ]
}